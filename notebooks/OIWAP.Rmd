---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.1'
      jupytext_version: 1.2.4
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

# Introduction
Calculate the average price, weighted by increases in open interest


### Imports
Import libraries and write settings here.

```{python}
# Data manipulation
import pandas as pd
import numpy as np

# Options for pandas
pd.options.display.max_columns = 50
pd.options.display.max_rows = 30

# Display all cell outputs
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = 'all'

from IPython import get_ipython
ipython = get_ipython()

# autoreload extension
if 'autoreload' not in ipython.extension_manager.loaded:
    %load_ext autoreload

# %autoreload 2

# Visualizations
import plotly.plotly as py
import plotly.graph_objs as go
from plotly.offline import iplot, init_notebook_mode
init_notebook_mode(connected=True)

import cufflinks as cf
cf.go_offline(connected=True)
cf.set_config_file(theme='white')
```

```{python}
from plotly.subplots import make_subplots
```

```{python}
from src import *
```

# Analysis/Modeling

```{python}
import arctic
from arctic.date import DateRange
```

```{python}
a = arctic.Arctic('localhost')
bm = a['bitmex']
```

```{python}
start = '8/26/2019'
end = '8/27/2019'

date_range = DateRange(start, end)
```

```{python code_folding=c("0")}
def get_aggregated_trades(trades, size_col='size'):
    trades.rename(columns={size_col:'size'}, inplace=True)
    trades['price_size'] = trades['price'].multiply(trades['size'])
    agg = (
        trades
        .groupby([trades.index, trades['side']])
        .agg({'size':sum, 'price_size':sum})
        .reset_index()
        .set_index('date')
    )
    agg['price'] = agg['price_size'].divide(agg['size'])
    return agg
```

```{python}
trades = bm.read('trade', chunk_range=date_range)
trades = trades[trades['symbol']=='XBTUSD']
trades = get_aggregated_trades(trades)

oi = bm.read('open_interest', chunk_range=date_range)['open_interest']
oi = oi.groupby(oi.index).mean()

trades.head()
oi.head()
```

## Open Interest Changes

```{python code_folding=c("0", "12", "19", "32")}
def calc_weighted_avg_price(price, weight, grouper):
    grouper.rename('grouper', inplace=True)
    price_weight = price.multiply(weight)
    df = pd.concat([price_weight, weight], axis=1)
    grouped = df.groupby(grouper).sum()
    res = (
        grouped
        .iloc[:,0]
        .divide(grouped.iloc[:,1])
    )
    return res

def calc_weighted_anchored_price(price, weight, grouper):
    grouper.rename('grouper', inplace=True)
    price_weight = price.multiply(weight)
    df = pd.concat([price_weight, weight], axis=1)
    grouped = df.groupby(grouper).cumsum()
    return grouped.iloc[:,0].divide(grouped.iloc[:,1])

def get_resample_grouper(df, rs_freq):
    date_series = pd.Series(df.index, index=df.index).rename('name')
    grouper = (
        date_series
        .resample(rs_freq)
        .first()
        .reset_index()
        .set_index('name')
        .reindex(df.index)
        .ffill()
    )
    return grouper.iloc[:,0]

def align_index_grouper(df1, df2):
    """
    Creates a series by which to group on irregular timeseries on another
    """
    common_idx = df1.index.union(df2.index)
    s1 = pd.Series(index=common_idx)
    s2 = pd.Series(df2.index, index=df2.index)
    s1.loc[s2] = s2
    grouper = pd.to_datetime(s1.ffill()).reindex(df1.index)
    return grouper
```

```{python}
trade_grouper = align_index_grouper(trades, oi)
trade_group_oi = (
    calc_weighted_avg_price(trades['price'], trades['size'], trade_grouper)
    .reindex(oi.index)
    .ffill()
)
trade_group_oi
```

```{python}
lookback1 = 50
lookback2 = 10
diff = (oi.rolling(lookback).max() - oi.rolling(lookback).min()).rolling(lookback2).max()
index_changes = pd.Series(oi.index).diff(lookback) / np.timedelta64(1, 's')

index_changes.describe()
diff.describe()
```

```{python}
threshold = 10e6
breaks = ((diff.shift(1) > threshold) & (diff <= threshold))
diff.loc[breaks]
oi_grouper = breaks.astype(int).cumsum()
oi_grouper
```

```{python}
oi_delta = oi.diff().to_frame()
oi_delta['dummy'] = 0
oi_trimmed = oi_delta.max(axis=1)

oiwap = calc_weighted_anchored_price(trade_group_oi, oi_trimmed, oi_grouper)
```

```{python}
fig = go.Figure()

rs = trades['price'].resample('5T').first()

fig.add_trace(go.Scatter(
    x=oiwap.index,
    y=oiwap.values
))

fig.add_trace(go.Scatter(
    x=trade_group_oi.loc[breaks].index,
    y=trade_group_oi.loc[breaks].values,
    mode='markers'
))

fig.add_trace(go.Scatter(
    x=rs.index,
    y=rs.values
))

fig.show()
```

```{python}
oi.iplot()
```

## Weighted Average Calc

```{python}

```

# Results
Show graphs and stats here

```{python}
trades['price'].resample('4h').first().iplot()
oi.iplot()
```

# Conclusions and Next Steps
Summarize findings here
